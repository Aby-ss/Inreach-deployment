const fs = require('fs');
const path = require('path');
const axios = require('axios');
const readline = require('readline-sync');

const cosineSimilarity = (a, b) => {
  const dot = a.reduce((sum, ai, i) => sum + ai * b[i], 0);
  const magA = Math.sqrt(a.reduce((sum, ai) => sum + ai * ai, 0));
  const magB = Math.sqrt(b.reduce((sum, bi) => sum + bi * bi, 0));
  return dot / (magA * magB);
};

const CHUNKS_FILE = path.join(__dirname, 'data', 'chunks.json');
const NOTES_DIR = path.join(__dirname, 'data');

/**
 * ğŸ§  Embed query using Ollama
 */
async function embedText(text) {
  const res = await axios.post('http://localhost:11434/api/embeddings', {
    model: 'nomic-embed-text',
    prompt: text,
  });

  return res.data.embedding;
}

/**
 * ğŸ§© Get relevant chunks via cosine similarity
 */
async function getRelevantChunks(query, topK = 3) {
  const queryEmbedding = await embedText(query);
  const data = JSON.parse(fs.readFileSync(CHUNKS_FILE, 'utf8'));

  const scored = data.map(item => ({
    chunk: item.chunk,
    score: cosineSimilarity(queryEmbedding, item.embedding),
  }));

  return scored
    .sort((a, b) => b.score - a.score)
    .slice(0, topK)
    .map(item => item.chunk);
}

/**
 * ğŸ“š Load podcast notes from .txt files
 */
function loadPodcastNotes() {
  if (!fs.existsSync(NOTES_DIR)) return '';

  const files = fs.readdirSync(NOTES_DIR).filter(f => f.endsWith('.txt'));
  let combined = '';

  for (const file of files) {
    const content = fs.readFileSync(path.join(NOTES_DIR, file), 'utf8');
    combined += `--- ${file} ---\n${content}\n\n`;
  }

  return combined.trim();
}

/**
 * ğŸ¤– Query the LLM (e.g., mistral)
 */
async function queryLLM(prompt) {
  try {
    const res = await axios.post('http://localhost:11434/api/generate', {
      model: 'mistral',
      prompt,
      stream: false,
    });

    return res.data.response;
  } catch (err) {
    console.error('âŒ LLM error:', err.message);
    return '';
  }
}

/**
 * âœ… Check for cold email factors in the response
 */
function evaluateResponseFactors(response) {
  const checks = {
    intent: /intent|goal|objective|reason/i.test(response),
    personalization: /you|your team|congrats|noticed|saw|read/i.test(response),
    value: /benefit|value|help you|growth|increase|reduce|results/i.test(response),
    cta: /schedule|call|chat|book|reply|interested|connect/i.test(response),
    prospectCentric: /you|your|team|business|company/i.test(response) && !/we|our|my company/i.test(response)
  };

  console.log('ğŸ“‹ Quality Factor Checklist:\n');
  console.log(`ğŸ¯ Intent Present: ${checks.intent ? 'âœ…' : 'âŒ'}`);
  console.log(`ğŸ“Œ Personalized: ${checks.personalization ? 'âœ…' : 'âŒ'}`);
  console.log(`ğŸ’¥ Value-Centric: ${checks.value ? 'âœ…' : 'âŒ'}`);
  console.log(`ğŸš€ Has CTA: ${checks.cta ? 'âœ…' : 'âŒ'}`);
  console.log(`ğŸ” Prospect-Focused: ${checks.prospectCentric ? 'âœ…' : 'âŒ'}`);
  console.log('\n' + '='.repeat(60) + '\n');
}

/**
 * ğŸ§  Main assistant
 */
async function runAssistant() {
  const query = readline.question('ğŸ’¬ What do you want help with?\n> ');
  const responses = readline.questionInt('ğŸ” How many responses would you like?\n> ');

  const podcastNotes = loadPodcastNotes();
  const relevantChunks = await getRelevantChunks(query);
  const context = relevantChunks.join('\n\n');

  const finalPrompt = `
You are an expert cold email strategist. Use the podcast notes and chunks below to answer the userâ€™s question.

ğŸ“š Podcast Notes:
${podcastNotes || 'No notes found.'}

ğŸ§© Chunks:
${context}

â“ Question:
${query}
`;

  console.log('\nğŸ¤– Thinking...\n');

  for (let i = 1; i <= responses; i++) {
    console.log(`ğŸ§  Response ${i}:\n`);
    const output = await queryLLM(finalPrompt);
    console.log(output);

    // ğŸ§¾ Evaluate cold email quality factors
    evaluateResponseFactors(output);

    console.log('-'.repeat(60) + '\n');
  }
}

runAssistant();
